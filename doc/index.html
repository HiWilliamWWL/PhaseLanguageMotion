<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Learn to Predict How Humans Manipulate Large-Sized Objects From Interactive Motions</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">PhaseFusion: A Diffusion-based Periodic
Parameterized Motion Generation Framework</span>
		<br>
		<br>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr align=center>
					Weilin Wan, Yiming Huang, Shutong Wu, Taku Komura, Wenping Wang, Dinesh Jayaraman, Lingjie Liu
				</tr>
			</table>
			<br>
			<!-- 
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://ieeexplore.ieee.org/abstract/document/9714029'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/HiWilliamWWL/how-humans-manipulate-large-sized-objects'>[GitHub]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://drive.google.com/drive/folders/174k-o7UFuIZg8BsZRbDGcAbVskKsF36r?usp=sharing'>[Dataset]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
			-->
			
		</table>
	</center>


	<table align=center width=850px>
		<center><h1>Introduction</h1></center>
		<tr>
			<td>
				In this study, we introduce a learning-based method for generating high-quality human motion sequences from text descriptions (e.g., ``A person walks forward"). Existing techniques struggle with motion diversity and smooth transitions due to limited text-to-motion datasets and reliance on full-body skeletal pose representations. To address this, we develop a network encoder that converts motion sequences into periodic signals, capturing the local periodicity of motions in time and space. We also propose a conditional diffusion model for predicting periodic motion parameters based on text descriptions and the starting pose. Our approach outperforms current methods, generating a broader variety of high-quality motions with natural transitions, especially in longer sequences.
			</td>
		</tr>
	</table>
	<hr>
	<br>

		<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:500px" src="./resources/pipeline_new.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					<center>Method Overview: We first learn a network encoder to transform the motion space
into a learned periodic parameterized phase space by minimizing the reconstruction errors between
the original motions and the motions formed by periodic parameters via Inverse FFT. Next, we train a
conditional diffusion model to predict the periodic parameters with text prompts and a starting pose
as input</center>
				</td>
			</tr>
		</table>
	</center>

	

	<hr>
	<center><h1>Video</h1></center>
	<p align="center">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/_dljuki13VU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	</p>


	<!-- 
	<hr>
	<table align=center width=450px>
		<center><h1>Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><br>
				<b>Learn to Predict How Humans Manipulate Large-Sized Objects From Interactive Motions</b><br>
				2022 IEEE Robotics and Automation Letters<br>
			</td>
		</tr>
	</table>
	<br>

	

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="https://ieeexplore.ieee.org/abstract/document/9714029">[Paper]</a>
				<a href="https://github.com/HiWilliamWWL/how-humans-manipulate-large-sized-objects">[GitHub]</a>
				<a href="https://drive.google.com/drive/folders/174k-o7UFuIZg8BsZRbDGcAbVskKsF36r?usp=sharing">[Dataset]</a>
				<a href="./resources/bibtex.txt">[Slides]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Citation</h1></center>
					<a href="./resources/bibtex.txt">[Bibtex]</a>
					<pre>
@article{wan2022learn,
	title={Learn to Predict How Humans Manipulate Large-Sized Objects From Interactive Motions},
	author={Wan, Weilin and Yang, Lei and Liu, Lingjie and Zhang, Zhuoying and Jia, Ruixing and Choi, Yi-King 
		and Pan, Jia and Theobalt, Christian and Komura, Taku and Wang, Wenping},
	journal={IEEE Robotics and Automation Letters},
	volume={7},
	number={2},
	pages={4702--4709},
	year={2022},
	publisher={IEEE}
}						  
					</pre>
				</left>
			</td>
		</tr>
	</table>
<hr>
<br>
-->
<span style="font-size:15px">Please contact <font style="color:blue">wanwl@connect.hku.hk</font> if you have any questions!</span>
<br>
<br>
<br>
<br>
<span style="font-size:13px">Thanks <a href="http://richzhang.github.io/">Richard Zhang</a> for the website <a href="https://github.com/richzhang/webpage-template">template</a>.</span>
</body>
</html>

